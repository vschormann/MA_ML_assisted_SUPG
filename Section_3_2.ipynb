{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7539c598",
   "metadata": {},
   "source": [
    "# Section 3_1 MLP networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f901dea",
   "metadata": {},
   "source": [
    "## General CNN modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d945a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils.supervised_dataset import supervised_dataset as dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.transforms import flattening_transform, reshape_transform, reindex_transform, create_cell_ind_to_grid, create_flattening_index_set,channeled_flattening_transform\n",
    "\n",
    "\n",
    "\n",
    "class resblock(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.layer(x)\n",
    "        return z+x\n",
    "\n",
    "\n",
    "from utils.transforms import cells_from_flat_array_ind\n",
    "\n",
    "class cnn_layer(torch.nn.Module):\n",
    "    def __init__(self, d, C, dim=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(d):\n",
    "            layers.append(\n",
    "                resblock(\n",
    "                    torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(in_channels=C,out_channels=C,kernel_size=3, padding=1,dtype=torch.float32, device='mps'),\n",
    "                    torch.nn.LeakyReLU(),\n",
    "                    torch.nn.BatchNorm2d(C, device='mps')\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        self.net = torch.nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class cnn2d(torch.nn.Module):\n",
    "    def __init__(self, d, w):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=13,out_channels=w,kernel_size=3, padding=1,dtype=torch.float32, device='mps'),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            cnn_layer(d=d,C=w,dim=2),\n",
    "            torch.nn.Conv2d(in_channels=w,out_channels=int(np.floor(w/2)),kernel_size=3, padding=1,dtype=torch.float32, device='mps'),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(in_channels=int(np.floor(w/2)),out_channels=int(np.floor(w/4)), kernel_size=3, padding=1,dtype=torch.float32, device='mps'),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(in_channels=int(np.floor(w/4)),out_channels=int(np.floor(w/8)), kernel_size=3, padding=1,dtype=torch.float32, device='mps'),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(in_channels=int(np.floor(w/8)),out_channels=1, kernel_size=3, padding=0,dtype=torch.float32, device='mps'),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09ba8e",
   "metadata": {},
   "source": [
    "## Global MLSemilocal CNN datasets and training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f7edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(dataloader, nn, optimizer, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    nn.train()\n",
    "    train_loss = 0.0\n",
    "    for batch, (x, t) in enumerate(dataloader):\n",
    "        y_pred = nn(x)\n",
    "\n",
    "        loss = loss_fn(y_pred,t)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= num_batches\n",
    "    print(f\"Train loss: {train_loss:>7f}\")\n",
    "    return(train_loss)\n",
    "\n",
    "def test_loop(dataloader, nn, loss_fn):\n",
    "    nn.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, t in dataloader:\n",
    "            y_pred = nn(x)\n",
    "\n",
    "            loss = loss_fn(y_pred,t)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test loss: {test_loss:>8f} \\n\")\n",
    "    return(test_loss)\n",
    "\n",
    "\n",
    "def train(\n",
    "        device,\n",
    "        nn,\n",
    "        lr,\n",
    "        gamma,\n",
    "        step_size,\n",
    "        epochs, \n",
    "        train_set_input_dir,\n",
    "        train_set_target_dir,\n",
    "        test_set_input_dir,\n",
    "        test_set_target_dir,\n",
    "        batch_size,\n",
    "        err_threshold = 1.0,\n",
    "        train_loss_file = None, \n",
    "        test_loss_file = None,\n",
    "        model_dir = None,\n",
    "        figure = None,\n",
    "        figure_file = None,\n",
    "        conv_type=2,\n",
    "):\n",
    "    H,W = 32,32\n",
    "    if conv_type == 0:\n",
    "        target_transform = flattening_transform(torch.arange(H*W), 1, True)\n",
    "        transform = flattening_transform(create_flattening_index_set(H+2,W+2,False),13, True)\n",
    "    if conv_type == 1:\n",
    "        target_transform = flattening_transform(torch.arange(H*W), 1, True)\n",
    "        transform = channeled_flattening_transform(create_flattening_index_set(H+2,W+2,False),13)\n",
    "    if conv_type == 2:\n",
    "        target_transform = reshape_transform(H,W)\n",
    "        transform = None\n",
    "\n",
    "    train_set = dataset(\n",
    "        input_dir=train_set_input_dir, \n",
    "        target_dir=train_set_target_dir, \n",
    "        transform=transform, \n",
    "        target_transform=target_transform, \n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    test_set = dataset(\n",
    "        input_dir=test_set_input_dir, \n",
    "        target_dir=test_set_target_dir, \n",
    "        transform=transform, \n",
    "        target_transform=target_transform, \n",
    "        device=device\n",
    "    )\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "    \n",
    "    model = nn\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=step_size, gamma=gamma)\n",
    "    train_loss_array = np.array([])\n",
    "    test_loss_array = np.array([])\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss_array = np.append(\n",
    "            train_loss_array, \n",
    "            train_loop(\n",
    "                dataloader=train_loader,\n",
    "                nn=model,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn\n",
    "                )\n",
    "        )\n",
    "        scheduler.step()\n",
    "        test_loss = test_loop(\n",
    "                dataloader=test_loader, \n",
    "                nn=model, \n",
    "                loss_fn=loss_fn\n",
    "            )\n",
    "        test_loss_array = np.append(\n",
    "            test_loss_array,\n",
    "            test_loss\n",
    "        )\n",
    "        if model_dir and test_loss < err_threshold:\n",
    "            torch.save(model.state_dict(), f'{model_dir}.pth')\n",
    "            err_threshold = test_loss\n",
    "    if train_loss_file:\n",
    "        np.save(file=train_loss_file, arr=train_loss_array)\n",
    "    if test_loss_file:\n",
    "        np.save(file=test_loss_file, arr=test_loss_array)\n",
    "    if figure:\n",
    "        clear_output()\n",
    "        x= np.linspace(1,len(train_loss_array),len(train_loss_array))\n",
    "\n",
    "        plt.plot(x, train_loss_array, label= 'Train loss', linestyle='-',)\n",
    "        plt.plot(x, test_loss_array,label='Test loss', linestyle='-')\n",
    "\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        if figure_file:\n",
    "            plt.savefig(figure_file)\n",
    "        plt.show()\n",
    "    return train_loss_array, test_loss_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d2204",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e94b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 703489\n"
     ]
    }
   ],
   "source": [
    "w = 128\n",
    "d = 4\n",
    "print(f\"Parameters: {sum(p.numel() for p in cnn2d(d,w).parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b758dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 703489\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.148032\n",
      "Test loss: 0.190493 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.018115\n",
      "Test loss: 0.132688 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.011502\n",
      "Test loss: 0.066520 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008684\n",
      "Test loss: 0.030987 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006214\n",
      "Test loss: 0.016498 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007238\n",
      "Test loss: 0.014321 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005065\n",
      "Test loss: 0.009383 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004961\n",
      "Test loss: 0.009740 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004157\n",
      "Test loss: 0.007938 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004807\n",
      "Test loss: 0.006869 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003689\n",
      "Test loss: 0.004894 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003109\n",
      "Test loss: 0.004464 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003362\n",
      "Test loss: 0.003779 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003659\n",
      "Test loss: 0.002984 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003706\n",
      "Test loss: 0.002805 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.002963\n",
      "Test loss: 0.002537 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004186\n",
      "Test loss: 0.002513 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003443\n",
      "Test loss: 0.002409 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003778\n",
      "Test loss: 0.002378 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003095\n",
      "Test loss: 0.002373 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.151054\n",
      "Test loss: 0.219619 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.025710\n",
      "Test loss: 0.128759 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.011135\n",
      "Test loss: 0.052971 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.007459\n",
      "Test loss: 0.025333 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006064\n",
      "Test loss: 0.015798 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.004881\n",
      "Test loss: 0.009592 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004393\n",
      "Test loss: 0.006852 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003896\n",
      "Test loss: 0.005670 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003886\n",
      "Test loss: 0.004972 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004358\n",
      "Test loss: 0.003827 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003732\n",
      "Test loss: 0.003532 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003597\n",
      "Test loss: 0.003440 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003077\n",
      "Test loss: 0.003088 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003809\n",
      "Test loss: 0.002731 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003629\n",
      "Test loss: 0.002591 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003661\n",
      "Test loss: 0.002506 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.002912\n",
      "Test loss: 0.002468 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003421\n",
      "Test loss: 0.002452 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004014\n",
      "Test loss: 0.002440 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003094\n",
      "Test loss: 0.002439 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.178059\n",
      "Test loss: 0.189350 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.025958\n",
      "Test loss: 0.111666 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.013114\n",
      "Test loss: 0.060974 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.011779\n",
      "Test loss: 0.036744 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.009785\n",
      "Test loss: 0.016929 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007053\n",
      "Test loss: 0.011552 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006880\n",
      "Test loss: 0.008387 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.006139\n",
      "Test loss: 0.006236 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005077\n",
      "Test loss: 0.005569 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004603\n",
      "Test loss: 0.005280 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004886\n",
      "Test loss: 0.004472 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004400\n",
      "Test loss: 0.003816 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004413\n",
      "Test loss: 0.003625 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004171\n",
      "Test loss: 0.003437 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003956\n",
      "Test loss: 0.003290 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004165\n",
      "Test loss: 0.003180 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004498\n",
      "Test loss: 0.003148 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004094\n",
      "Test loss: 0.003136 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004348\n",
      "Test loss: 0.003140 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004295\n",
      "Test loss: 0.003131 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.189559\n",
      "Test loss: 0.236138 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.025797\n",
      "Test loss: 0.122984 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012441\n",
      "Test loss: 0.051559 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.007951\n",
      "Test loss: 0.033750 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006025\n",
      "Test loss: 0.019661 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005129\n",
      "Test loss: 0.014140 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004780\n",
      "Test loss: 0.009952 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003998\n",
      "Test loss: 0.008379 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003867\n",
      "Test loss: 0.006823 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004052\n",
      "Test loss: 0.006134 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003397\n",
      "Test loss: 0.005162 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003898\n",
      "Test loss: 0.004412 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003756\n",
      "Test loss: 0.003671 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003373\n",
      "Test loss: 0.003265 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004239\n",
      "Test loss: 0.003056 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003971\n",
      "Test loss: 0.002934 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003500\n",
      "Test loss: 0.002830 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003413\n",
      "Test loss: 0.002799 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003885\n",
      "Test loss: 0.002790 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003390\n",
      "Test loss: 0.002796 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.208649\n",
      "Test loss: 0.351993 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.032709\n",
      "Test loss: 0.215775 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.013492\n",
      "Test loss: 0.106966 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009176\n",
      "Test loss: 0.061401 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008541\n",
      "Test loss: 0.036021 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.009036\n",
      "Test loss: 0.019495 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004857\n",
      "Test loss: 0.011065 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005635\n",
      "Test loss: 0.008798 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004746\n",
      "Test loss: 0.005435 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.005516\n",
      "Test loss: 0.004046 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.005016\n",
      "Test loss: 0.003357 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003756\n",
      "Test loss: 0.003165 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004144\n",
      "Test loss: 0.002870 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003811\n",
      "Test loss: 0.002542 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003544\n",
      "Test loss: 0.002451 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004103\n",
      "Test loss: 0.002380 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003990\n",
      "Test loss: 0.002375 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004477\n",
      "Test loss: 0.002405 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003890\n",
      "Test loss: 0.002324 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004834\n",
      "Test loss: 0.002333 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.444927\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.444459\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.444932\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.444916\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.444934\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.444470\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.444921\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.444940\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.444477\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.444937\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.444484\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.444936\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.444916\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.444935\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.444924\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.444935\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.444911\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.444938\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.444923\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.444927\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.196327\n",
      "Test loss: 0.239588 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.030747\n",
      "Test loss: 0.138087 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.018906\n",
      "Test loss: 0.069904 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.012236\n",
      "Test loss: 0.033680 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008069\n",
      "Test loss: 0.023704 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.008143\n",
      "Test loss: 0.012663 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005631\n",
      "Test loss: 0.009914 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.007574\n",
      "Test loss: 0.007079 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005898\n",
      "Test loss: 0.006175 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.006536\n",
      "Test loss: 0.004655 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.005751\n",
      "Test loss: 0.004383 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004848\n",
      "Test loss: 0.003846 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004807\n",
      "Test loss: 0.003562 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004630\n",
      "Test loss: 0.003507 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004351\n",
      "Test loss: 0.003453 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004224\n",
      "Test loss: 0.003366 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004113\n",
      "Test loss: 0.003301 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004401\n",
      "Test loss: 0.003284 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.005435\n",
      "Test loss: 0.003277 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003962\n",
      "Test loss: 0.003262 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.169075\n",
      "Test loss: 0.182412 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.031506\n",
      "Test loss: 0.132610 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.018508\n",
      "Test loss: 0.077430 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.014008\n",
      "Test loss: 0.034533 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.009678\n",
      "Test loss: 0.024826 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007502\n",
      "Test loss: 0.009156 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.007039\n",
      "Test loss: 0.010279 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.006452\n",
      "Test loss: 0.006106 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005487\n",
      "Test loss: 0.005181 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.005751\n",
      "Test loss: 0.005009 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.005407\n",
      "Test loss: 0.004404 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004712\n",
      "Test loss: 0.004035 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.005323\n",
      "Test loss: 0.003912 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.006080\n",
      "Test loss: 0.003726 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004617\n",
      "Test loss: 0.003650 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004637\n",
      "Test loss: 0.003589 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004282\n",
      "Test loss: 0.003556 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004773\n",
      "Test loss: 0.003543 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004682\n",
      "Test loss: 0.003572 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004477\n",
      "Test loss: 0.003545 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.191529\n",
      "Test loss: 0.298381 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.023684\n",
      "Test loss: 0.145160 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.011793\n",
      "Test loss: 0.091201 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.010561\n",
      "Test loss: 0.041339 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007539\n",
      "Test loss: 0.021412 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005537\n",
      "Test loss: 0.013507 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004597\n",
      "Test loss: 0.009151 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003942\n",
      "Test loss: 0.006017 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003708\n",
      "Test loss: 0.004496 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004762\n",
      "Test loss: 0.004022 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003541\n",
      "Test loss: 0.003431 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.006344\n",
      "Test loss: 0.003135 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004217\n",
      "Test loss: 0.002690 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003361\n",
      "Test loss: 0.002451 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004663\n",
      "Test loss: 0.002381 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004651\n",
      "Test loss: 0.002269 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003463\n",
      "Test loss: 0.002241 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003568\n",
      "Test loss: 0.002218 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004834\n",
      "Test loss: 0.002241 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003840\n",
      "Test loss: 0.002228 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.202500\n",
      "Test loss: 0.285504 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.037654\n",
      "Test loss: 0.169546 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.015747\n",
      "Test loss: 0.062683 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009290\n",
      "Test loss: 0.049324 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006170\n",
      "Test loss: 0.022427 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.004906\n",
      "Test loss: 0.016895 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004339\n",
      "Test loss: 0.010643 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003921\n",
      "Test loss: 0.006728 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003805\n",
      "Test loss: 0.005193 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003725\n",
      "Test loss: 0.004623 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003364\n",
      "Test loss: 0.003899 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003398\n",
      "Test loss: 0.003423 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003549\n",
      "Test loss: 0.003093 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003680\n",
      "Test loss: 0.002875 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003448\n",
      "Test loss: 0.002736 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003678\n",
      "Test loss: 0.002642 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003533\n",
      "Test loss: 0.002605 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003526\n",
      "Test loss: 0.002586 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003355\n",
      "Test loss: 0.002586 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003782\n",
      "Test loss: 0.002573 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.149029\n",
      "Test loss: 0.210038 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.021868\n",
      "Test loss: 0.104876 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012235\n",
      "Test loss: 0.062949 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.010393\n",
      "Test loss: 0.034424 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007559\n",
      "Test loss: 0.019071 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006958\n",
      "Test loss: 0.015929 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005521\n",
      "Test loss: 0.009291 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005123\n",
      "Test loss: 0.007441 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004150\n",
      "Test loss: 0.005748 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004092\n",
      "Test loss: 0.004630 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004166\n",
      "Test loss: 0.003952 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004294\n",
      "Test loss: 0.003602 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004226\n",
      "Test loss: 0.003372 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003981\n",
      "Test loss: 0.003140 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003928\n",
      "Test loss: 0.003062 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003571\n",
      "Test loss: 0.002975 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003731\n",
      "Test loss: 0.002951 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003801\n",
      "Test loss: 0.002927 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003803\n",
      "Test loss: 0.002918 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004525\n",
      "Test loss: 0.002913 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.408038\n",
      "Test loss: 0.445425 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.072731\n",
      "Test loss: 0.198079 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.022156\n",
      "Test loss: 0.083678 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.014887\n",
      "Test loss: 0.059199 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.013766\n",
      "Test loss: 0.020649 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.009259\n",
      "Test loss: 0.018318 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.007167\n",
      "Test loss: 0.010067 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005834\n",
      "Test loss: 0.008573 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005011\n",
      "Test loss: 0.007262 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004473\n",
      "Test loss: 0.005567 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.005191\n",
      "Test loss: 0.004891 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.005224\n",
      "Test loss: 0.004455 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.005123\n",
      "Test loss: 0.004009 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.005487\n",
      "Test loss: 0.003735 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.005202\n",
      "Test loss: 0.003547 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004849\n",
      "Test loss: 0.003423 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004564\n",
      "Test loss: 0.003353 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004355\n",
      "Test loss: 0.003325 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004197\n",
      "Test loss: 0.003320 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004204\n",
      "Test loss: 0.003335 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.205695\n",
      "Test loss: 0.243168 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.019526\n",
      "Test loss: 0.129661 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012689\n",
      "Test loss: 0.050402 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009878\n",
      "Test loss: 0.029108 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007192\n",
      "Test loss: 0.016831 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005838\n",
      "Test loss: 0.012174 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005086\n",
      "Test loss: 0.008283 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004357\n",
      "Test loss: 0.006531 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004674\n",
      "Test loss: 0.005367 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004386\n",
      "Test loss: 0.004709 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004189\n",
      "Test loss: 0.004090 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003689\n",
      "Test loss: 0.003688 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003885\n",
      "Test loss: 0.003409 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.005787\n",
      "Test loss: 0.003225 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004157\n",
      "Test loss: 0.003080 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004992\n",
      "Test loss: 0.003109 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003902\n",
      "Test loss: 0.003016 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.005943\n",
      "Test loss: 0.003128 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004066\n",
      "Test loss: 0.002978 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004084\n",
      "Test loss: 0.002991 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.211870\n",
      "Test loss: 0.233945 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.038111\n",
      "Test loss: 0.139227 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.022996\n",
      "Test loss: 0.064987 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.013909\n",
      "Test loss: 0.047652 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.012759\n",
      "Test loss: 0.021146 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.013017\n",
      "Test loss: 0.014979 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.011274\n",
      "Test loss: 0.010604 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.008289\n",
      "Test loss: 0.010610 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.009059\n",
      "Test loss: 0.006874 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.007517\n",
      "Test loss: 0.006053 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.006915\n",
      "Test loss: 0.005630 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.006277\n",
      "Test loss: 0.005388 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.007238\n",
      "Test loss: 0.004779 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.006620\n",
      "Test loss: 0.004409 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.005979\n",
      "Test loss: 0.004259 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.006278\n",
      "Test loss: 0.004189 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.006219\n",
      "Test loss: 0.004127 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.005625\n",
      "Test loss: 0.004104 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.006150\n",
      "Test loss: 0.004100 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.006307\n",
      "Test loss: 0.004092 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.217757\n",
      "Test loss: 0.318326 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.023226\n",
      "Test loss: 0.097660 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012295\n",
      "Test loss: 0.056726 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008381\n",
      "Test loss: 0.022292 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006063\n",
      "Test loss: 0.013977 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.003955\n",
      "Test loss: 0.008275 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.003574\n",
      "Test loss: 0.005126 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.002924\n",
      "Test loss: 0.004434 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003050\n",
      "Test loss: 0.003510 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003000\n",
      "Test loss: 0.002904 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003007\n",
      "Test loss: 0.002766 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.002857\n",
      "Test loss: 0.002679 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.002665\n",
      "Test loss: 0.002373 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003154\n",
      "Test loss: 0.002195 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.002758\n",
      "Test loss: 0.002070 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.002830\n",
      "Test loss: 0.001986 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.002627\n",
      "Test loss: 0.001975 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.002909\n",
      "Test loss: 0.001982 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.002728\n",
      "Test loss: 0.001968 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.002820\n",
      "Test loss: 0.001960 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.183388\n",
      "Test loss: 0.280212 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.024495\n",
      "Test loss: 0.158329 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012716\n",
      "Test loss: 0.084621 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009134\n",
      "Test loss: 0.037080 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007158\n",
      "Test loss: 0.028526 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006216\n",
      "Test loss: 0.011451 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004153\n",
      "Test loss: 0.008806 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003772\n",
      "Test loss: 0.005581 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003938\n",
      "Test loss: 0.004501 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003053\n",
      "Test loss: 0.003354 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003823\n",
      "Test loss: 0.002813 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003198\n",
      "Test loss: 0.002551 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003511\n",
      "Test loss: 0.002462 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003557\n",
      "Test loss: 0.002387 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004004\n",
      "Test loss: 0.002319 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003384\n",
      "Test loss: 0.002281 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.002744\n",
      "Test loss: 0.002242 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.002931\n",
      "Test loss: 0.002188 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003549\n",
      "Test loss: 0.002214 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003254\n",
      "Test loss: 0.002174 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.197573\n",
      "Test loss: 0.240200 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.033705\n",
      "Test loss: 0.166840 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.016749\n",
      "Test loss: 0.106043 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.013407\n",
      "Test loss: 0.053905 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.009565\n",
      "Test loss: 0.021516 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006506\n",
      "Test loss: 0.012531 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006248\n",
      "Test loss: 0.007448 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004727\n",
      "Test loss: 0.005377 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005074\n",
      "Test loss: 0.004312 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004785\n",
      "Test loss: 0.003641 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003822\n",
      "Test loss: 0.003172 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004658\n",
      "Test loss: 0.002926 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004191\n",
      "Test loss: 0.002888 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004417\n",
      "Test loss: 0.002735 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003637\n",
      "Test loss: 0.002566 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004245\n",
      "Test loss: 0.002522 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003435\n",
      "Test loss: 0.002506 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004259\n",
      "Test loss: 0.002542 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004480\n",
      "Test loss: 0.002601 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004662\n",
      "Test loss: 0.002543 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.249214\n",
      "Test loss: 0.373901 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.044844\n",
      "Test loss: 0.198865 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.017608\n",
      "Test loss: 0.108812 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.012401\n",
      "Test loss: 0.050470 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.011936\n",
      "Test loss: 0.032295 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.009211\n",
      "Test loss: 0.014202 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005822\n",
      "Test loss: 0.011632 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.008074\n",
      "Test loss: 0.007485 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.007122\n",
      "Test loss: 0.006074 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004639\n",
      "Test loss: 0.005606 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.005428\n",
      "Test loss: 0.004659 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.005406\n",
      "Test loss: 0.004227 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004644\n",
      "Test loss: 0.003965 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.005070\n",
      "Test loss: 0.003571 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004591\n",
      "Test loss: 0.003395 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004826\n",
      "Test loss: 0.003305 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004832\n",
      "Test loss: 0.003239 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.005711\n",
      "Test loss: 0.003242 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004661\n",
      "Test loss: 0.003217 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004430\n",
      "Test loss: 0.003221 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.156078\n",
      "Test loss: 0.227154 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.022272\n",
      "Test loss: 0.098971 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.008003\n",
      "Test loss: 0.054647 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.007121\n",
      "Test loss: 0.029119 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.005282\n",
      "Test loss: 0.019732 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.004337\n",
      "Test loss: 0.012968 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004155\n",
      "Test loss: 0.009995 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003334\n",
      "Test loss: 0.006666 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.002832\n",
      "Test loss: 0.005723 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.002927\n",
      "Test loss: 0.004431 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.002887\n",
      "Test loss: 0.003564 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.002832\n",
      "Test loss: 0.003068 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.002806\n",
      "Test loss: 0.002658 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.002657\n",
      "Test loss: 0.002403 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.002814\n",
      "Test loss: 0.002168 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003091\n",
      "Test loss: 0.002081 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.002675\n",
      "Test loss: 0.002033 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.002844\n",
      "Test loss: 0.002032 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.002785\n",
      "Test loss: 0.002020 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.002809\n",
      "Test loss: 0.002012 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.137110\n",
      "Test loss: 0.235939 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.026649\n",
      "Test loss: 0.120510 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012818\n",
      "Test loss: 0.057799 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.012025\n",
      "Test loss: 0.028847 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.009126\n",
      "Test loss: 0.025838 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007953\n",
      "Test loss: 0.012620 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005821\n",
      "Test loss: 0.010279 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005115\n",
      "Test loss: 0.007046 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004510\n",
      "Test loss: 0.005915 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004495\n",
      "Test loss: 0.005252 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003911\n",
      "Test loss: 0.004549 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004143\n",
      "Test loss: 0.004028 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004159\n",
      "Test loss: 0.003597 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004151\n",
      "Test loss: 0.003335 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003905\n",
      "Test loss: 0.003142 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003748\n",
      "Test loss: 0.003050 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004034\n",
      "Test loss: 0.003019 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004100\n",
      "Test loss: 0.002993 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003747\n",
      "Test loss: 0.003002 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003838\n",
      "Test loss: 0.002958 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.256519\n",
      "Test loss: 0.338463 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.031277\n",
      "Test loss: 0.161810 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.014327\n",
      "Test loss: 0.083310 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.011688\n",
      "Test loss: 0.045218 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008147\n",
      "Test loss: 0.021232 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006803\n",
      "Test loss: 0.018297 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004980\n",
      "Test loss: 0.008021 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004875\n",
      "Test loss: 0.007469 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004511\n",
      "Test loss: 0.005197 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004373\n",
      "Test loss: 0.004067 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003903\n",
      "Test loss: 0.003776 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003542\n",
      "Test loss: 0.003132 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003299\n",
      "Test loss: 0.002699 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003533\n",
      "Test loss: 0.002537 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003696\n",
      "Test loss: 0.002417 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003096\n",
      "Test loss: 0.002369 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003036\n",
      "Test loss: 0.002350 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003002\n",
      "Test loss: 0.002340 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003271\n",
      "Test loss: 0.002330 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003146\n",
      "Test loss: 0.002337 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.144119\n",
      "Test loss: 0.224032 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.016907\n",
      "Test loss: 0.133553 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.007904\n",
      "Test loss: 0.059451 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008374\n",
      "Test loss: 0.029838 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.004889\n",
      "Test loss: 0.019591 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.003965\n",
      "Test loss: 0.011363 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.003973\n",
      "Test loss: 0.008364 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003338\n",
      "Test loss: 0.006584 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003028\n",
      "Test loss: 0.006161 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003477\n",
      "Test loss: 0.005107 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003421\n",
      "Test loss: 0.004020 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.002918\n",
      "Test loss: 0.003598 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.002745\n",
      "Test loss: 0.003036 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.002738\n",
      "Test loss: 0.002645 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.002855\n",
      "Test loss: 0.002349 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.002757\n",
      "Test loss: 0.002198 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.002640\n",
      "Test loss: 0.002152 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003254\n",
      "Test loss: 0.002146 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003099\n",
      "Test loss: 0.002138 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.002899\n",
      "Test loss: 0.002133 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.145071\n",
      "Test loss: 0.226646 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.020137\n",
      "Test loss: 0.139251 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012981\n",
      "Test loss: 0.075410 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.007933\n",
      "Test loss: 0.032977 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.005205\n",
      "Test loss: 0.019564 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005489\n",
      "Test loss: 0.012557 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004008\n",
      "Test loss: 0.008845 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003535\n",
      "Test loss: 0.006040 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004213\n",
      "Test loss: 0.005083 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004884\n",
      "Test loss: 0.004228 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003021\n",
      "Test loss: 0.003970 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003103\n",
      "Test loss: 0.003243 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003854\n",
      "Test loss: 0.002700 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003361\n",
      "Test loss: 0.002490 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003750\n",
      "Test loss: 0.002330 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.002760\n",
      "Test loss: 0.002134 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.002602\n",
      "Test loss: 0.002071 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003186\n",
      "Test loss: 0.002040 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003264\n",
      "Test loss: 0.002036 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003846\n",
      "Test loss: 0.002034 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.180587\n",
      "Test loss: 0.307564 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.045039\n",
      "Test loss: 0.154378 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.017724\n",
      "Test loss: 0.075036 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.011497\n",
      "Test loss: 0.031695 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008851\n",
      "Test loss: 0.025465 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005512\n",
      "Test loss: 0.011832 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006148\n",
      "Test loss: 0.009786 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005151\n",
      "Test loss: 0.005761 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005099\n",
      "Test loss: 0.004793 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004603\n",
      "Test loss: 0.004500 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004863\n",
      "Test loss: 0.003898 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.005242\n",
      "Test loss: 0.003646 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004979\n",
      "Test loss: 0.003193 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.005043\n",
      "Test loss: 0.003019 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004406\n",
      "Test loss: 0.002941 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003638\n",
      "Test loss: 0.002840 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004319\n",
      "Test loss: 0.002818 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004858\n",
      "Test loss: 0.002802 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003649\n",
      "Test loss: 0.002783 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003388\n",
      "Test loss: 0.002780 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.159224\n",
      "Test loss: 0.263923 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.030670\n",
      "Test loss: 0.117539 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.013899\n",
      "Test loss: 0.049299 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008706\n",
      "Test loss: 0.030066 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.005920\n",
      "Test loss: 0.017083 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005137\n",
      "Test loss: 0.011238 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004112\n",
      "Test loss: 0.007913 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003967\n",
      "Test loss: 0.005409 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003451\n",
      "Test loss: 0.004271 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003309\n",
      "Test loss: 0.003621 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003238\n",
      "Test loss: 0.003155 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004012\n",
      "Test loss: 0.002887 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003201\n",
      "Test loss: 0.002729 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003139\n",
      "Test loss: 0.002638 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003025\n",
      "Test loss: 0.002570 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003124\n",
      "Test loss: 0.002532 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003285\n",
      "Test loss: 0.002525 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003336\n",
      "Test loss: 0.002500 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003359\n",
      "Test loss: 0.002491 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003325\n",
      "Test loss: 0.002500 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.192426\n",
      "Test loss: 0.273643 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.028450\n",
      "Test loss: 0.154036 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012617\n",
      "Test loss: 0.078536 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009394\n",
      "Test loss: 0.042815 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006379\n",
      "Test loss: 0.018940 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007054\n",
      "Test loss: 0.011633 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005299\n",
      "Test loss: 0.007237 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005642\n",
      "Test loss: 0.005646 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004439\n",
      "Test loss: 0.004463 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003805\n",
      "Test loss: 0.003701 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004394\n",
      "Test loss: 0.003329 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003615\n",
      "Test loss: 0.003039 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004005\n",
      "Test loss: 0.002901 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003492\n",
      "Test loss: 0.002713 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004259\n",
      "Test loss: 0.002629 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004274\n",
      "Test loss: 0.002589 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004162\n",
      "Test loss: 0.002563 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004882\n",
      "Test loss: 0.002528 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003785\n",
      "Test loss: 0.002510 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003516\n",
      "Test loss: 0.002505 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.151830\n",
      "Test loss: 0.263881 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.022458\n",
      "Test loss: 0.138069 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.011928\n",
      "Test loss: 0.071800 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009364\n",
      "Test loss: 0.040293 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.010103\n",
      "Test loss: 0.028449 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006850\n",
      "Test loss: 0.016985 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005249\n",
      "Test loss: 0.011559 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005414\n",
      "Test loss: 0.010019 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004905\n",
      "Test loss: 0.007969 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004255\n",
      "Test loss: 0.007218 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004027\n",
      "Test loss: 0.005805 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004045\n",
      "Test loss: 0.004973 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004624\n",
      "Test loss: 0.004159 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004933\n",
      "Test loss: 0.003510 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.005201\n",
      "Test loss: 0.003171 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003992\n",
      "Test loss: 0.002998 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004078\n",
      "Test loss: 0.002948 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003917\n",
      "Test loss: 0.002919 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004446\n",
      "Test loss: 0.002885 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003931\n",
      "Test loss: 0.002872 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.173015\n",
      "Test loss: 0.257989 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.021593\n",
      "Test loss: 0.162933 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012580\n",
      "Test loss: 0.084790 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009425\n",
      "Test loss: 0.032646 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006320\n",
      "Test loss: 0.023696 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006112\n",
      "Test loss: 0.011866 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006249\n",
      "Test loss: 0.006579 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003890\n",
      "Test loss: 0.004890 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003893\n",
      "Test loss: 0.003845 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003261\n",
      "Test loss: 0.002903 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003190\n",
      "Test loss: 0.002678 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003119\n",
      "Test loss: 0.002457 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003714\n",
      "Test loss: 0.002392 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003213\n",
      "Test loss: 0.002203 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003317\n",
      "Test loss: 0.002155 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003188\n",
      "Test loss: 0.002144 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003462\n",
      "Test loss: 0.002118 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003250\n",
      "Test loss: 0.002099 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003035\n",
      "Test loss: 0.002092 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003237\n",
      "Test loss: 0.002106 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.110474\n",
      "Test loss: 0.220276 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.019706\n",
      "Test loss: 0.108907 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.011308\n",
      "Test loss: 0.049660 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009622\n",
      "Test loss: 0.029639 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006455\n",
      "Test loss: 0.016028 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005068\n",
      "Test loss: 0.013520 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005677\n",
      "Test loss: 0.009025 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004580\n",
      "Test loss: 0.008111 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004020\n",
      "Test loss: 0.007666 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003605\n",
      "Test loss: 0.005803 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003672\n",
      "Test loss: 0.005118 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003919\n",
      "Test loss: 0.004314 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003463\n",
      "Test loss: 0.003606 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003504\n",
      "Test loss: 0.003164 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003613\n",
      "Test loss: 0.002914 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003873\n",
      "Test loss: 0.002768 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003575\n",
      "Test loss: 0.002714 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003651\n",
      "Test loss: 0.002689 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003237\n",
      "Test loss: 0.002672 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003603\n",
      "Test loss: 0.002672 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.195346\n",
      "Test loss: 0.297044 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.033612\n",
      "Test loss: 0.127108 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.015095\n",
      "Test loss: 0.081597 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008784\n",
      "Test loss: 0.052392 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006730\n",
      "Test loss: 0.022054 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006959\n",
      "Test loss: 0.016546 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005049\n",
      "Test loss: 0.010112 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004743\n",
      "Test loss: 0.008560 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004770\n",
      "Test loss: 0.006370 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004317\n",
      "Test loss: 0.005139 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004517\n",
      "Test loss: 0.004713 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004271\n",
      "Test loss: 0.003949 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004438\n",
      "Test loss: 0.003354 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004181\n",
      "Test loss: 0.003078 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003840\n",
      "Test loss: 0.002919 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.005372\n",
      "Test loss: 0.002820 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004530\n",
      "Test loss: 0.002824 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004597\n",
      "Test loss: 0.002767 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003856\n",
      "Test loss: 0.002766 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004523\n",
      "Test loss: 0.002757 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.128629\n",
      "Test loss: 0.214107 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.023302\n",
      "Test loss: 0.125623 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012140\n",
      "Test loss: 0.064531 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009261\n",
      "Test loss: 0.030068 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007257\n",
      "Test loss: 0.014565 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006224\n",
      "Test loss: 0.010770 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005522\n",
      "Test loss: 0.007915 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005044\n",
      "Test loss: 0.005487 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004650\n",
      "Test loss: 0.004930 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004097\n",
      "Test loss: 0.005228 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004172\n",
      "Test loss: 0.004301 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004306\n",
      "Test loss: 0.003658 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003977\n",
      "Test loss: 0.003365 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003625\n",
      "Test loss: 0.003138 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003851\n",
      "Test loss: 0.002953 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004178\n",
      "Test loss: 0.002892 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003555\n",
      "Test loss: 0.002801 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003817\n",
      "Test loss: 0.002827 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003509\n",
      "Test loss: 0.002814 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003418\n",
      "Test loss: 0.002772 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.185824\n",
      "Test loss: 0.262080 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.024816\n",
      "Test loss: 0.127862 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012849\n",
      "Test loss: 0.053719 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.007652\n",
      "Test loss: 0.039067 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006432\n",
      "Test loss: 0.021410 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005380\n",
      "Test loss: 0.013059 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004423\n",
      "Test loss: 0.009954 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004162\n",
      "Test loss: 0.006619 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004137\n",
      "Test loss: 0.005409 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003923\n",
      "Test loss: 0.004955 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003955\n",
      "Test loss: 0.004292 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003938\n",
      "Test loss: 0.003761 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003417\n",
      "Test loss: 0.003457 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003566\n",
      "Test loss: 0.003217 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003763\n",
      "Test loss: 0.002979 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003936\n",
      "Test loss: 0.002851 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003383\n",
      "Test loss: 0.002816 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003687\n",
      "Test loss: 0.002803 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003546\n",
      "Test loss: 0.002793 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003285\n",
      "Test loss: 0.002788 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.182521\n",
      "Test loss: 0.273577 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.037233\n",
      "Test loss: 0.132544 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.014746\n",
      "Test loss: 0.067470 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.010372\n",
      "Test loss: 0.047972 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008426\n",
      "Test loss: 0.020176 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006601\n",
      "Test loss: 0.018001 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006780\n",
      "Test loss: 0.009529 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.007256\n",
      "Test loss: 0.006623 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004925\n",
      "Test loss: 0.005290 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.006630\n",
      "Test loss: 0.005331 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004451\n",
      "Test loss: 0.003986 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004388\n",
      "Test loss: 0.003471 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004469\n",
      "Test loss: 0.003280 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004698\n",
      "Test loss: 0.003167 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003907\n",
      "Test loss: 0.003111 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004411\n",
      "Test loss: 0.003074 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.005198\n",
      "Test loss: 0.003058 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004299\n",
      "Test loss: 0.003064 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004833\n",
      "Test loss: 0.003130 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004393\n",
      "Test loss: 0.003035 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.130120\n",
      "Test loss: 0.233275 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.019251\n",
      "Test loss: 0.118801 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.014035\n",
      "Test loss: 0.064039 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.011197\n",
      "Test loss: 0.037564 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008333\n",
      "Test loss: 0.020109 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006557\n",
      "Test loss: 0.012614 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004755\n",
      "Test loss: 0.006570 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004927\n",
      "Test loss: 0.005491 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003990\n",
      "Test loss: 0.004716 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003522\n",
      "Test loss: 0.003697 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003217\n",
      "Test loss: 0.003069 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003776\n",
      "Test loss: 0.002876 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003300\n",
      "Test loss: 0.002719 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003396\n",
      "Test loss: 0.002587 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003502\n",
      "Test loss: 0.002493 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003351\n",
      "Test loss: 0.002453 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003058\n",
      "Test loss: 0.002437 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003345\n",
      "Test loss: 0.002429 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003242\n",
      "Test loss: 0.002416 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003119\n",
      "Test loss: 0.002410 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.208847\n",
      "Test loss: 0.276960 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.027095\n",
      "Test loss: 0.141396 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.014666\n",
      "Test loss: 0.058982 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009329\n",
      "Test loss: 0.031786 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008135\n",
      "Test loss: 0.018288 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006904\n",
      "Test loss: 0.011259 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006742\n",
      "Test loss: 0.006835 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004882\n",
      "Test loss: 0.005830 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005082\n",
      "Test loss: 0.004871 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004586\n",
      "Test loss: 0.004109 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004077\n",
      "Test loss: 0.003933 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.005042\n",
      "Test loss: 0.003774 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004105\n",
      "Test loss: 0.003483 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003896\n",
      "Test loss: 0.003321 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003835\n",
      "Test loss: 0.003223 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004521\n",
      "Test loss: 0.003175 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004203\n",
      "Test loss: 0.003152 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004031\n",
      "Test loss: 0.003133 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004069\n",
      "Test loss: 0.003121 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004041\n",
      "Test loss: 0.003118 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.223943\n",
      "Test loss: 0.232815 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.027596\n",
      "Test loss: 0.136596 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012967\n",
      "Test loss: 0.070183 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.009936\n",
      "Test loss: 0.032513 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008506\n",
      "Test loss: 0.020161 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007859\n",
      "Test loss: 0.014382 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.007088\n",
      "Test loss: 0.008506 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005690\n",
      "Test loss: 0.006734 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005467\n",
      "Test loss: 0.006459 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004727\n",
      "Test loss: 0.006169 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.005065\n",
      "Test loss: 0.004882 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004598\n",
      "Test loss: 0.004459 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004888\n",
      "Test loss: 0.004200 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004345\n",
      "Test loss: 0.003789 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004571\n",
      "Test loss: 0.003545 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004532\n",
      "Test loss: 0.003411 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004215\n",
      "Test loss: 0.003363 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.005630\n",
      "Test loss: 0.003349 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004702\n",
      "Test loss: 0.003313 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.005070\n",
      "Test loss: 0.003358 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.189576\n",
      "Test loss: 0.322708 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.021980\n",
      "Test loss: 0.171535 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.010897\n",
      "Test loss: 0.062951 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008444\n",
      "Test loss: 0.037428 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006558\n",
      "Test loss: 0.020393 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005732\n",
      "Test loss: 0.010452 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004150\n",
      "Test loss: 0.007897 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.003939\n",
      "Test loss: 0.005187 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003457\n",
      "Test loss: 0.004011 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003125\n",
      "Test loss: 0.003512 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003695\n",
      "Test loss: 0.003055 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.002783\n",
      "Test loss: 0.002764 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003253\n",
      "Test loss: 0.002584 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.002944\n",
      "Test loss: 0.002438 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003672\n",
      "Test loss: 0.002389 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003052\n",
      "Test loss: 0.002308 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003032\n",
      "Test loss: 0.002273 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003462\n",
      "Test loss: 0.002268 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003200\n",
      "Test loss: 0.002255 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003348\n",
      "Test loss: 0.002255 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.234575\n",
      "Test loss: 0.299556 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.034730\n",
      "Test loss: 0.168354 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.019992\n",
      "Test loss: 0.081213 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.014776\n",
      "Test loss: 0.037548 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.013333\n",
      "Test loss: 0.021143 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.009743\n",
      "Test loss: 0.015222 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.009361\n",
      "Test loss: 0.007166 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.006518\n",
      "Test loss: 0.006194 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.006283\n",
      "Test loss: 0.005661 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.007065\n",
      "Test loss: 0.004647 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.005656\n",
      "Test loss: 0.004105 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004510\n",
      "Test loss: 0.003951 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.005185\n",
      "Test loss: 0.003765 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004856\n",
      "Test loss: 0.003579 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004328\n",
      "Test loss: 0.003485 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004899\n",
      "Test loss: 0.003397 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.005033\n",
      "Test loss: 0.003342 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.005486\n",
      "Test loss: 0.003336 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.005435\n",
      "Test loss: 0.003358 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004960\n",
      "Test loss: 0.003350 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.175231\n",
      "Test loss: 0.234659 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.028516\n",
      "Test loss: 0.121586 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.015671\n",
      "Test loss: 0.057766 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.011444\n",
      "Test loss: 0.034721 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008745\n",
      "Test loss: 0.014753 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007600\n",
      "Test loss: 0.012005 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006091\n",
      "Test loss: 0.007117 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005854\n",
      "Test loss: 0.007131 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.006005\n",
      "Test loss: 0.005449 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.005175\n",
      "Test loss: 0.005101 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.006402\n",
      "Test loss: 0.004268 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.005208\n",
      "Test loss: 0.004553 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.005416\n",
      "Test loss: 0.003920 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003944\n",
      "Test loss: 0.003493 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004543\n",
      "Test loss: 0.003306 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004045\n",
      "Test loss: 0.003159 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004752\n",
      "Test loss: 0.003109 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.006023\n",
      "Test loss: 0.003104 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.005054\n",
      "Test loss: 0.003103 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004372\n",
      "Test loss: 0.003084 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.214876\n",
      "Test loss: 0.264620 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.036864\n",
      "Test loss: 0.137986 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.018063\n",
      "Test loss: 0.067853 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.011798\n",
      "Test loss: 0.036060 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008868\n",
      "Test loss: 0.020230 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007557\n",
      "Test loss: 0.014473 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.007340\n",
      "Test loss: 0.010401 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005207\n",
      "Test loss: 0.007831 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004997\n",
      "Test loss: 0.007017 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004806\n",
      "Test loss: 0.006705 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004576\n",
      "Test loss: 0.005833 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004632\n",
      "Test loss: 0.004832 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004161\n",
      "Test loss: 0.004421 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004517\n",
      "Test loss: 0.004027 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003989\n",
      "Test loss: 0.003715 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004006\n",
      "Test loss: 0.003564 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004231\n",
      "Test loss: 0.003507 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004411\n",
      "Test loss: 0.003478 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004191\n",
      "Test loss: 0.003462 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004518\n",
      "Test loss: 0.003455 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.444920\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.444486\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.444920\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.444934\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.444944\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.444913\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.444931\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.444911\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.444917\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.444927\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.444952\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.444914\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.444939\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.444955\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.444929\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.444951\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.444946\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.444912\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.444945\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.444929\n",
      "Test loss: 0.445437 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.198238\n",
      "Test loss: 0.253070 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.038098\n",
      "Test loss: 0.104756 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.016566\n",
      "Test loss: 0.067946 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.010592\n",
      "Test loss: 0.035644 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007139\n",
      "Test loss: 0.020363 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006269\n",
      "Test loss: 0.013152 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005463\n",
      "Test loss: 0.008637 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005162\n",
      "Test loss: 0.007345 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004962\n",
      "Test loss: 0.005054 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.005184\n",
      "Test loss: 0.004078 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004207\n",
      "Test loss: 0.003457 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004399\n",
      "Test loss: 0.003244 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004577\n",
      "Test loss: 0.003105 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004252\n",
      "Test loss: 0.003011 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004213\n",
      "Test loss: 0.002982 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.005444\n",
      "Test loss: 0.002971 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004514\n",
      "Test loss: 0.002940 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004396\n",
      "Test loss: 0.002915 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004220\n",
      "Test loss: 0.002903 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004541\n",
      "Test loss: 0.002937 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.139088\n",
      "Test loss: 0.223019 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.023603\n",
      "Test loss: 0.129902 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.018254\n",
      "Test loss: 0.067973 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.010848\n",
      "Test loss: 0.046606 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007883\n",
      "Test loss: 0.013245 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005333\n",
      "Test loss: 0.012628 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004837\n",
      "Test loss: 0.006492 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004461\n",
      "Test loss: 0.004235 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004312\n",
      "Test loss: 0.003689 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004396\n",
      "Test loss: 0.003307 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003968\n",
      "Test loss: 0.003143 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003905\n",
      "Test loss: 0.002792 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003529\n",
      "Test loss: 0.002697 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004402\n",
      "Test loss: 0.002658 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003487\n",
      "Test loss: 0.002614 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004895\n",
      "Test loss: 0.002650 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003445\n",
      "Test loss: 0.002582 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003621\n",
      "Test loss: 0.002568 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004886\n",
      "Test loss: 0.002624 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003429\n",
      "Test loss: 0.002556 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.129853\n",
      "Test loss: 0.181102 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.021609\n",
      "Test loss: 0.096385 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.010013\n",
      "Test loss: 0.060700 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.007536\n",
      "Test loss: 0.034122 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.004913\n",
      "Test loss: 0.016822 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.004658\n",
      "Test loss: 0.013497 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.004850\n",
      "Test loss: 0.010258 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004075\n",
      "Test loss: 0.006119 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.003797\n",
      "Test loss: 0.006649 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003967\n",
      "Test loss: 0.006145 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003309\n",
      "Test loss: 0.005057 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003385\n",
      "Test loss: 0.004099 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003525\n",
      "Test loss: 0.003313 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003100\n",
      "Test loss: 0.003033 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003288\n",
      "Test loss: 0.002756 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003545\n",
      "Test loss: 0.002671 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003419\n",
      "Test loss: 0.002551 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003492\n",
      "Test loss: 0.002536 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003805\n",
      "Test loss: 0.002550 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003885\n",
      "Test loss: 0.002554 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.227498\n",
      "Test loss: 0.303795 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.029125\n",
      "Test loss: 0.133952 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012917\n",
      "Test loss: 0.054470 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008985\n",
      "Test loss: 0.040904 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.009097\n",
      "Test loss: 0.023358 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007181\n",
      "Test loss: 0.016010 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005883\n",
      "Test loss: 0.013858 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004935\n",
      "Test loss: 0.009575 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004975\n",
      "Test loss: 0.007803 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004547\n",
      "Test loss: 0.007580 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004635\n",
      "Test loss: 0.005903 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003902\n",
      "Test loss: 0.005079 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004644\n",
      "Test loss: 0.004322 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003920\n",
      "Test loss: 0.003825 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004303\n",
      "Test loss: 0.003393 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003633\n",
      "Test loss: 0.003224 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.005240\n",
      "Test loss: 0.003144 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004738\n",
      "Test loss: 0.003110 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004768\n",
      "Test loss: 0.003107 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004334\n",
      "Test loss: 0.003102 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.228393\n",
      "Test loss: 0.325805 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.029505\n",
      "Test loss: 0.161547 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.015956\n",
      "Test loss: 0.080965 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.011459\n",
      "Test loss: 0.050820 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.008803\n",
      "Test loss: 0.020235 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007540\n",
      "Test loss: 0.021289 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005639\n",
      "Test loss: 0.011509 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.006360\n",
      "Test loss: 0.008188 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004793\n",
      "Test loss: 0.007244 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004554\n",
      "Test loss: 0.006061 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004650\n",
      "Test loss: 0.005187 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004092\n",
      "Test loss: 0.004319 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.004336\n",
      "Test loss: 0.003855 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004898\n",
      "Test loss: 0.003568 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004679\n",
      "Test loss: 0.003382 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004425\n",
      "Test loss: 0.003258 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.003864\n",
      "Test loss: 0.003226 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004993\n",
      "Test loss: 0.003226 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003906\n",
      "Test loss: 0.003209 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004514\n",
      "Test loss: 0.003208 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.156009\n",
      "Test loss: 0.208843 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.030671\n",
      "Test loss: 0.101061 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.017599\n",
      "Test loss: 0.070485 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.015097\n",
      "Test loss: 0.047632 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.009945\n",
      "Test loss: 0.012968 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.007748\n",
      "Test loss: 0.015684 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006959\n",
      "Test loss: 0.009184 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005872\n",
      "Test loss: 0.006008 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.005609\n",
      "Test loss: 0.005688 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004390\n",
      "Test loss: 0.005019 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.006002\n",
      "Test loss: 0.004218 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004556\n",
      "Test loss: 0.003629 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003971\n",
      "Test loss: 0.003328 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004777\n",
      "Test loss: 0.003078 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004689\n",
      "Test loss: 0.002988 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.004555\n",
      "Test loss: 0.002942 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004327\n",
      "Test loss: 0.002861 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003790\n",
      "Test loss: 0.002828 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003721\n",
      "Test loss: 0.002807 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.004040\n",
      "Test loss: 0.002818 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.176453\n",
      "Test loss: 0.218216 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.025412\n",
      "Test loss: 0.114815 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.012146\n",
      "Test loss: 0.063865 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008661\n",
      "Test loss: 0.041202 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.006555\n",
      "Test loss: 0.015490 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.004960\n",
      "Test loss: 0.011897 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.005084\n",
      "Test loss: 0.008571 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.006276\n",
      "Test loss: 0.006110 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004697\n",
      "Test loss: 0.005232 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.003374\n",
      "Test loss: 0.004057 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003434\n",
      "Test loss: 0.003589 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.003982\n",
      "Test loss: 0.003010 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.003729\n",
      "Test loss: 0.002753 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003864\n",
      "Test loss: 0.002395 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.003410\n",
      "Test loss: 0.002293 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003571\n",
      "Test loss: 0.002241 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004448\n",
      "Test loss: 0.002242 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.003170\n",
      "Test loss: 0.002196 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003741\n",
      "Test loss: 0.002209 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.002943\n",
      "Test loss: 0.002196 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.232525\n",
      "Test loss: 0.296945 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.036776\n",
      "Test loss: 0.166100 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.017646\n",
      "Test loss: 0.071910 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.013210\n",
      "Test loss: 0.032557 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.009314\n",
      "Test loss: 0.022591 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.006894\n",
      "Test loss: 0.011099 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006121\n",
      "Test loss: 0.008734 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.004893\n",
      "Test loss: 0.006986 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004947\n",
      "Test loss: 0.005948 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.004258\n",
      "Test loss: 0.005722 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.003935\n",
      "Test loss: 0.004704 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004378\n",
      "Test loss: 0.003966 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.005008\n",
      "Test loss: 0.003586 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.003732\n",
      "Test loss: 0.003377 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.004422\n",
      "Test loss: 0.003142 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.003875\n",
      "Test loss: 0.003031 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.004506\n",
      "Test loss: 0.002985 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004934\n",
      "Test loss: 0.003024 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.003946\n",
      "Test loss: 0.002963 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.003809\n",
      "Test loss: 0.002928 \n",
      "\n",
      "Run: \n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 0.165128\n",
      "Test loss: 0.205314 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 0.024649\n",
      "Test loss: 0.124812 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 0.015159\n",
      "Test loss: 0.069204 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 0.008958\n",
      "Test loss: 0.041150 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 0.007247\n",
      "Test loss: 0.020928 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 0.005880\n",
      "Test loss: 0.013793 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 0.006444\n",
      "Test loss: 0.008966 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 0.005079\n",
      "Test loss: 0.006875 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 0.004580\n",
      "Test loss: 0.005834 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 0.005451\n",
      "Test loss: 0.005043 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 0.004608\n",
      "Test loss: 0.004200 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 0.004568\n",
      "Test loss: 0.003935 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 0.005000\n",
      "Test loss: 0.003497 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 0.004196\n",
      "Test loss: 0.003278 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 0.005905\n",
      "Test loss: 0.003137 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 0.005166\n",
      "Test loss: 0.003108 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 0.005421\n",
      "Test loss: 0.003133 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 0.004722\n",
      "Test loss: 0.003057 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 0.004308\n",
      "Test loss: 0.003063 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 0.005255\n",
      "Test loss: 0.003065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w = 128\n",
    "d = 4\n",
    "print(f\"Parameters: {sum(p.numel() for p in cnn2d(d,w).parameters())}\")\n",
    "for k in range(50):\n",
    "    \n",
    "    print(f\"Run: \")\n",
    "    model2d=cnn2d(d,w)\n",
    "\n",
    "    train(\n",
    "        device='mps',\n",
    "        nn=model2d,\n",
    "        step_size=2,\n",
    "        lr=0.001,\n",
    "        gamma=0.5,\n",
    "        epochs=20,\n",
    "        train_set_input_dir = \"data/example_3_1/training_set/inputs/\",\n",
    "        train_set_target_dir = \"data/example_3_1/training_set/target_values/\",\n",
    "        test_set_input_dir = \"data/example_3_1/test_set/inputs/\",\n",
    "        test_set_target_dir = \"data/example_3_1/test_set/target_values/\",\n",
    "        batch_size=64,\n",
    "        err_threshold=1.0,\n",
    "        train_loss_file=f\"data/example_3_2/loss_arrays/train_loss_cnn_{k}\",\n",
    "        test_loss_file=f\"data/example_3_2/loss_arrays/test_loss_cnn_{k}\",\n",
    "        model_dir=f\"data/example_3_2/models/cnn_{k}\",\n",
    "        figure=None,\n",
    "        figure_file=None,\n",
    "        conv_type=2\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b78fd",
   "metadata": {},
   "source": [
    "## Visualization of the loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a48502f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "step = 50\n",
    "dir0 = \"data/example_3_1/loss_arrays/test_cMLP_narrow\"\n",
    "dir1 = \"data/example_3_1/loss_arrays/test_cMLP_10hidden\"\n",
    "dir2 = \"data/example_3_2/loss_arrays/test_loss_cnn\"\n",
    "\n",
    "\n",
    "\n",
    "def load_loss_arrays(dir, idx, threshold=None):\n",
    "    l = []\n",
    "    for k in idx:\n",
    "        arr = np.load(f\"{dir}_{k}.npy\")\n",
    "        if threshold:\n",
    "            if np.max(arr) < threshold:\n",
    "                l.append(arr)\n",
    "        else:\n",
    "            l.append(arr)\n",
    "    return np.stack(l, axis = 0)\n",
    "x = ['C', 'D', 'CNN']\n",
    "boxnarrow = load_loss_arrays(dir0, np.arange(step), None)\n",
    "boxhidden10 = load_loss_arrays(dir1, np.arange(step), None)\n",
    "boxcnn = load_loss_arrays(dir2, np.arange(step), None)\n",
    "boxavg = np.vstack(\n",
    "    [\n",
    "        np.min(boxnarrow, axis=1),\n",
    "        np.min(boxhidden10, axis=1),\n",
    "        np.min(boxcnn, axis=1)\n",
    "        ]\n",
    "    )\n",
    "bp = plt.boxplot(\n",
    "    boxavg.T, \n",
    "    labels=x, \n",
    "    widths=0.8, \n",
    "    patch_artist=True, \n",
    "    #meanline=True,\n",
    "    showmeans=True, \n",
    "    showfliers=False,\n",
    "    meanprops={'marker':'o', \"markerfacecolor\":\"yellow\", \"color\":\"yellow\",\"markeredgecolor\":\"black\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1.5},\n",
    "    boxprops={\"facecolor\": \"C0\", \"edgecolor\": \"white\",\n",
    "                \"linewidth\": 0.5},\n",
    "    whiskerprops={\"color\": \"C0\", \"linewidth\": 1.5},\n",
    "    capprops={\"color\": \"C0\", \"linewidth\": 1.5}\n",
    ")\n",
    "lower_whisker_y = bp['whiskers'][2].get_ydata()[1]\n",
    "lower_median = bp['medians'][1].get_ydata()[0]\n",
    "bp['means'][0].set_label('mean values')\n",
    "bp['medians'][0].set_label('median values')\n",
    "\n",
    "plt.axhline(lower_whisker_y, linestyle='--', linewidth=1, color='green', label='best overall')\n",
    "plt.axhline(lower_median, linestyle=':', linewidth=1.5, color='grey', label='lowest median')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylim(0.0006,0.005)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig('example_3_2_loss_boxplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8565c3c",
   "metadata": {},
   "source": [
    "# Reconstruct fem solver from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dolfinx import mesh as msh\n",
    "from mpi4py import MPI\n",
    "from utils.transforms import channeled_flattening_transform, create_flattening_index_set\n",
    "from utils.supervised_dataset import supervised_dataset as dataset\n",
    "import torch\n",
    "\n",
    "from utils.plotter import fem_plotter_grid\n",
    "\n",
    "test_set_input_dir = \"data/example_3_1/test_set/inputs/\"\n",
    "test_set_target_dir = \"data/example_3_1/test_set/target_values/\"\n",
    "test_set = dataset(input_dir=test_set_input_dir, target_dir=test_set_target_dir, transform=None, target_transform=None)\n",
    "\n",
    "\n",
    "nx , ny = 32,32\n",
    "dofmap = msh.create_unit_square(MPI.COMM_WORLD, nx, ny, msh.CellType.quadrilateral).geometry.dofmap\n",
    "ufl_domain = msh.create_unit_square(MPI.COMM_WORLD, nx, ny, msh.CellType.quadrilateral).ufl_domain()\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "def x_to_mesh(x, dofmap, ufl_domain, comm):\n",
    "    VtoC_fmap = torch.tensor(dofmap).flatten()\n",
    "    x = x[:8,1:,:]\n",
    "    x = x[:,:-1,:]\n",
    "    x = x[:8,:,1:]\n",
    "    x = x[:,:,:-1]\n",
    "    #h,w = \n",
    "    cellvs = channeled_flattening_transform(flat_key=create_flattening_index_set(nx,ny,continuous_traversal=False),C=8)(x[:8])\n",
    "    cellvs.T[0].reshape(-1,2)\n",
    "    pts = []\n",
    "    for vs in cellvs.T:\n",
    "        pts.append(vs.reshape(-1,2))\n",
    "    pts = torch.concat((pts))\n",
    "    idx = torch.arange(torch.max(VtoC_fmap)+1)\n",
    "    for j in range(len(idx)):\n",
    "        idx[j] = torch.where(VtoC_fmap==j)[0][0]\n",
    "\n",
    "    retval = torch.zeros((len(idx),3))\n",
    "    retval[:,0:2] = pts[idx]\n",
    "    return msh.create_mesh(comm=comm, cells=dofmap, x=retval.detach().numpy(),e=ufl_domain)\n",
    "\n",
    "\n",
    "\n",
    "from dolfinx import mesh as msh\n",
    "from mpi4py import MPI\n",
    "from dolfinx import fem\n",
    "from dolfinx import default_scalar_type\n",
    "import ufl\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils.FEniCSx_solver import FEniCSx_solver\n",
    "\n",
    "x = torch.load('data/example_3_1/training_set/inputs/x_1.pt')\n",
    "\n",
    "def x_to_fem_data(x_tensor, dofmap, ufl_domain, comm):\n",
    "    domain = x_to_mesh(x_tensor, dofmap, ufl_domain, comm)\n",
    "    Wh = fem.functionspace(domain, ('P', 2))\n",
    "    domain.topology.create_connectivity(domain.topology.dim - 1, domain.topology.dim)\n",
    "    boundary_facets = msh.exterior_facet_indices(domain.topology)\n",
    "    boundary_dofs = fem.locate_dofs_topological(Wh, domain.topology.dim-1, boundary_facets)\n",
    "    eps = fem.Constant(domain, default_scalar_type(1e-8))\n",
    "    c = fem.Constant(domain, default_scalar_type(0.0))\n",
    "    f = fem.Constant(domain, default_scalar_type(1.0))\n",
    "    bK = x_tensor[9:11, 1,1]\n",
    "    if torch.allclose(bK, torch.tensor([ 1.0, 0.0], dtype = bK.dtype)):\n",
    "        b = ufl.as_vector((fem.Constant(domain, default_scalar_type(1.0)),fem.Constant(domain, default_scalar_type(0.0))))\n",
    "        dir = 0\n",
    "\n",
    "    if torch.allclose(bK, torch.tensor([ -1.0, 0.0], dtype = bK.dtype)):\n",
    "        b = ufl.as_vector((fem.Constant(domain, default_scalar_type(-1.0)),fem.Constant(domain, default_scalar_type(0.0))))\n",
    "        dir = 0\n",
    "\n",
    "    if torch.allclose(bK, torch.tensor([ 0.0, 1.0], dtype = bK.dtype)):\n",
    "        b = ufl.as_vector((fem.Constant(domain, default_scalar_type(0.0)),fem.Constant(domain, default_scalar_type(1.0))))\n",
    "        dir = 1\n",
    "\n",
    "    if torch.allclose(bK, torch.tensor([ 0.0, -1.0], dtype = bK.dtype)):\n",
    "        b = ufl.as_vector((fem.Constant(domain, default_scalar_type(0.0)),fem.Constant(domain, default_scalar_type(-1.0))))\n",
    "        dir = 1\n",
    "\n",
    "    x = ufl.SpatialCoordinate(domain)\n",
    "    \n",
    "\n",
    "\n",
    "    uD = torch.concat((x_tensor[12,0,:],x_tensor[12,-1,:],x_tensor[12,:,0],x_tensor[12,:,-1]))\n",
    "    if torch.max(uD)>0.1:\n",
    "        ex_exp = x[dir]\n",
    "        if torch.min(bK) < 0:\n",
    "            ex_exp = 1 - ex_exp\n",
    "        uh = fem.Function(Wh)\n",
    "            \n",
    "        exp = fem.Expression(ex_exp, Wh.element.interpolation_points())\n",
    "\n",
    "        u_ex = fem.Function(Wh)\n",
    "        u_ex.interpolate(exp)\n",
    "        bcs = [fem.dirichletbc(u_ex, boundary_dofs)]\n",
    "    else:\n",
    "        ex_exp = x[dir]*(1-ufl.exp(-(1-x[dir])/eps))* (1 - (((ufl.exp(-(1-x[(dir+1)%2])/eps)  + ufl.exp(-(x[(dir+1)%2])/eps)))- ufl.exp(-(1)/eps))/(1-ufl.exp(-1/eps)))\n",
    "\n",
    "        if torch.min(bK) < 0:\n",
    "            ex_exp = (1-x[dir])*(1-ufl.exp(-(x[dir])/eps))* (1 - (((ufl.exp(-(1-x[(dir+1)%2])/eps)  + ufl.exp(-(x[(dir+1)%2])/eps)))- ufl.exp(-(1)/eps))/(1-ufl.exp(-1/eps)))\n",
    "    \n",
    "        uh = fem.Function(Wh)\n",
    "            \n",
    "        exp = fem.Expression(ex_exp, Wh.element.interpolation_points())\n",
    "\n",
    "        u_ex = fem.Function(Wh)\n",
    "        u_ex.interpolate(exp)\n",
    "        bcs = [fem.dirichletbc(fem.Constant(domain, default_scalar_type(0.0)), boundary_dofs, Wh)]\n",
    "\n",
    "    loss = (uh-u_ex)**2 * ufl.dx\n",
    "    pde_data = domain,Wh,uh,eps,b,c,f,None,bcs\n",
    "    return x_tensor, FEniCSx_solver(pde_data=pde_data, loss_form=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.set_weights(t.detach().numpy())\n",
    "grid = fem_plotter_grid(fs.uh.function_space)\n",
    "grid.add_data(fs.uh)\n",
    "import pyvista as pv\n",
    "\n",
    "p = pv.Plotter()\n",
    "\n",
    "p.add_mesh(grid.grid.warp_by_scalar(), show_edges=True)\n",
    "p.show()\n",
    "uD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4927e4f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'set_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m x,t = test_set[i]\n\u001b[32m      5\u001b[39m fs = x_to_fem_data(x, dofmap, ufl_domain, comm)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_weights\u001b[49m(t.detach().numpy())\n\u001b[32m      7\u001b[39m loss_arr.append(fs.loss())\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#print(f\"Nr. {i}: loss: {loss_arr[-1]}\")\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'set_weights'"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "loss_arr = []\n",
    "for i in range(len(test_set)):\n",
    "    x,t = test_set[i]\n",
    "    fs = x_to_fem_data(x, dofmap, ufl_domain, comm)\n",
    "    fs.set_weights(t.detach().numpy())\n",
    "    loss_arr.append(fs.loss())\n",
    "    \n",
    "    #print(f\"Nr. {i}: loss: {loss_arr[-1]}\")\n",
    "loss_arr = np.array(loss_arr)\n",
    "x = np.linspace(0,len(loss_arr), len(loss_arr))\n",
    "\n",
    "print(f\"test loss: {np.average(loss_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ba85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reassing_dtypes import reassign_dtypes\n",
    "\n",
    "reassign_dtypes(test_set, torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
